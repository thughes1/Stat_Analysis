{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7d443dc-3bea-4c20-8aa9-d51fbb8cbd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7094/2769870937.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df['Hour'] = subset_df['Hour'].apply(lambda x: int(x[1:2]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Borough: Barking and Dagenham\n",
      "Pearson's correlation coefficient: 0.1443491226033355\n",
      "p-value: 2.915970546029293e-82\n",
      "Borough: City of London\n",
      "Pearson's correlation coefficient: 0.030771107681112096\n",
      "p-value: 4.600854654514319e-05\n",
      "Borough: Croydon\n",
      "Pearson's correlation coefficient: 0.11936484685275214\n",
      "p-value: 1.1890448559495604e-56\n",
      "Borough: Ealing\n",
      "Pearson's correlation coefficient: 0.147765876275608\n",
      "p-value: 3.737205227448042e-86\n",
      "Borough: Greenwich\n",
      "Pearson's correlation coefficient: 0.18246207715406967\n",
      "p-value: 4.2653646068871797e-131\n",
      "Borough: Hackney\n",
      "Pearson's correlation coefficient: 0.08870246965614603\n",
      "p-value: 5.752296363109952e-32\n",
      "Borough: Havering\n",
      "Pearson's correlation coefficient: 0.16009895775898672\n",
      "p-value: 5.409873855359642e-101\n",
      "Borough: Islington\n",
      "Pearson's correlation coefficient: 0.14584928623338783\n",
      "p-value: 5.854568794732159e-84\n",
      "Borough: Lambeth\n",
      "Pearson's correlation coefficient: 0.15229818992069852\n",
      "p-value: 1.8337707157160713e-91\n",
      "Borough: Lewisham\n",
      "Pearson's correlation coefficient: 0.14675195970870886\n",
      "p-value: 5.462973844688349e-85\n",
      "Borough: Redbridge\n",
      "Pearson's correlation coefficient: 0.1960123833935228\n",
      "p-value: 2.243785745568117e-151\n",
      "Borough: Sutton\n",
      "Pearson's correlation coefficient: 0.07648346755600872\n",
      "p-value: 3.626461792546572e-24\n",
      "Borough: Wandsworth\n",
      "Pearson's correlation coefficient: 0.10641186225349698\n",
      "p-value: 2.5184873378575333e-45\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "import re\n",
    "\n",
    "def getTables():\n",
    "    emission = pd.read_csv('tblEmission.csv')\n",
    "    vehicle = pd.read_csv('tblVehicle.csv')\n",
    "    return pd.merge(emission, vehicle, on=['Date', 'Hour', 'Borough'])\n",
    "\n",
    "combined = getTables()\n",
    "#combined.to_csv('tblCombined.csv')\n",
    "# assuming you have two columns in your DataFrame called 'group1' and 'group2'\n",
    "#stat, p = ttest_ind(combined['All_Vehicles'], combined['Hour'])\n",
    "#print(p)\n",
    "'''\n",
    "if p < 0.01:  # significance level of 0.05\n",
    "    print('The difference is statistically significant.')\n",
    "else:\n",
    "    print('The difference is not statistically significant.')\n",
    "'''\n",
    "'''\n",
    "# Calculate the correlation between two fields\n",
    "correlation = combined['no2'].corr(combined['All_Vehicles'])\n",
    "\n",
    "correlation, p_value = spearmanr(combined['All_Vehicles'], combined['no2'])\n",
    "print(\"Spearman's rank correlation coefficient: \", correlation)\n",
    "print(\"p-value: \", p_value)\n",
    "\n",
    "# Print the correlation coefficient\n",
    "print(\"Correlation coefficient: \", correlation)\n",
    "\n",
    "correlation, p_value = pearsonr(combined['no2'], combined['All_Vehicles'])\n",
    "print(\"Pearson's correlation coefficient: \", correlation)\n",
    "print(\"p-value: \", p_value)\n",
    "'''\n",
    "\n",
    "# Loop through each borough in the dataframe\n",
    "boroughs = combined['Borough'].unique()\n",
    "\n",
    "for borough in boroughs:\n",
    "    # Subset the dataframe by borough\n",
    "    subset_df = combined[combined['Borough'] == borough]\n",
    "    subset_df['Hour'] = subset_df['Hour'].apply(lambda x: int(x[1:2]))\n",
    "\n",
    "    # Calculate Pearson's correlation coefficient and p-value between two fields\n",
    "    correlation, p_value = pearsonr(subset_df['Hour'], subset_df['no2'])\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Borough:\", borough)\n",
    "    print(\"Pearson's correlation coefficient:\", correlation)\n",
    "    print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7a08654-ef5b-4b6b-a44b-5e6b5033af70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Borough: Barking and Dagenham\n",
      "Pearson's correlation coefficient: 0.031398443075806345\n",
      "p-value: 0.47155645929462586\n",
      "Borough: Bexley\n",
      "Pearson's correlation coefficient: -0.014535219281399097\n",
      "p-value: 0.6370665355131596\n",
      "Borough: City of London\n",
      "Pearson's correlation coefficient: 0.01942688833268514\n",
      "p-value: 0.7646218535970865\n",
      "Borough: Croydon\n",
      "Pearson's correlation coefficient: 0.07823210020201894\n",
      "p-value: 0.0023807002006269217\n",
      "Borough: Ealing\n",
      "Pearson's correlation coefficient: 0.007577253467082252\n",
      "p-value: 0.8068135842073738\n",
      "Borough: Enfield\n",
      "Pearson's correlation coefficient: 0.025642893674814482\n",
      "p-value: 0.4330273226252488\n",
      "Borough: Greenwich\n",
      "Pearson's correlation coefficient: 0.012733516821203434\n",
      "p-value: 0.6850405925014033\n",
      "Borough: Hackney\n",
      "Pearson's correlation coefficient: 0.03251292398950662\n",
      "p-value: 0.41938388435219187\n",
      "Borough: Haringey\n",
      "Pearson's correlation coefficient: 0.04291691547166833\n",
      "p-value: 0.21077362506343433\n",
      "Borough: Havering\n",
      "Pearson's correlation coefficient: 0.03951545306213594\n",
      "p-value: 0.20488184255412858\n",
      "Borough: Islington\n",
      "Pearson's correlation coefficient: 0.05312912810795379\n",
      "p-value: 0.18396825322850657\n",
      "Borough: Lambeth\n",
      "Pearson's correlation coefficient: 0.0614456013788649\n",
      "p-value: 0.05424437522844581\n",
      "Borough: Lewisham\n",
      "Pearson's correlation coefficient: 0.043053566013482286\n",
      "p-value: 0.16309276677202927\n",
      "Borough: Redbridge\n",
      "Pearson's correlation coefficient: 0.02040251190133612\n",
      "p-value: 0.5896955558686718\n",
      "Borough: Southwark\n",
      "Pearson's correlation coefficient: 0.044622445139936046\n",
      "p-value: 0.19635746807165338\n",
      "Borough: Sutton\n",
      "Pearson's correlation coefficient: 0.08200386877861987\n",
      "p-value: 0.029124212514546177\n",
      "Borough: Wandsworth\n",
      "Pearson's correlation coefficient: 0.009170682404862462\n",
      "p-value: 0.7854037266945992\n",
      "Borough: Westminster\n",
      "Pearson's correlation coefficient: 0.014228421623595288\n",
      "p-value: 0.6359852177268454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7094/3362615767.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df['Hour'] = subset_df['Hour'].apply(lambda x: int(x[1:2]))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def getTables():\n",
    "    emission = pd.read_csv('tblEmission.csv')\n",
    "    vehicle = pd.read_csv('missingData.csv')\n",
    "    return pd.merge(emission, vehicle, on=['Date', 'Hour', 'Borough'])\n",
    "combined = getTables()\n",
    "#combined.to_csv('combined2.csv')\n",
    "# Loop through each borough in the dataframe\n",
    "boroughs = combined['Borough'].unique()\n",
    "\n",
    "for borough in boroughs:\n",
    "    # Subset the dataframe by borough\n",
    "    subset_df = combined[combined['Borough'] == borough]\n",
    "    subset_df['Hour'] = subset_df['Hour'].apply(lambda x: int(x[1:2]))\n",
    "\n",
    "    # Calculate Pearson's correlation coefficient and p-value between two fields\n",
    "    correlation, p_value = pearsonr(subset_df['Hour'], subset_df['All_Vehicles'])\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Borough:\", borough)\n",
    "    print(\"Pearson's correlation coefficient:\", correlation)\n",
    "    print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f770f14b-1d0e-48b7-941d-470fef7070ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m tbl_emission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtblEmission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# join tbl_emission with dim_borough, dim_month, dim_year, and tbl_vehicle\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m joined_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtbl_emission\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_borough\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBorough\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim_month\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtbl_emission\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmonth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmonth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\\\n\u001b[1;32m     13\u001b[0m                 \u001b[38;5;241m.\u001b[39mmerge(dim_year, left_on\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mto_datetime(tbl_emission[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m)\\\n\u001b[1;32m     14\u001b[0m                 \u001b[38;5;241m.\u001b[39mmerge(tbl_vehicle, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBorough\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(joined_data)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# calculate the required averages\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:9190\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   9171\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   9172\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   9173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9186\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   9187\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   9188\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[0;32m-> 9190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9199\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9200\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py:106\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    105\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m--> 106\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py:699\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cross \u001b[38;5;241m=\u001b[39m cross_col\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# note this function has side effects\u001b[39;00m\n\u001b[1;32m    695\u001b[0m (\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[0;32m--> 699\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py:1100\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     right_keys\u001b[38;5;241m.\u001b[39mappend(right\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m-> 1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m lk \u001b[38;5;241m==\u001b[39m rk:\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;66;03m# avoid key upcast in corner case (length-0)\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(left) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1103\u001b[0m         right_drop\u001b[38;5;241m.\u001b[39mappend(rk)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py:1537\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__nonzero__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe truth value of a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is ambiguous. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1540\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#// TODO get dim tables with headings\n",
    "# load dimension tables from CSV files\n",
    "dim_borough = pd.read_csv('DimBorough.csv')\n",
    "dim_month = pd.read_csv('DimMonth.csv')\n",
    "dim_year = pd.read_csv('DimYear.csv')\n",
    "tbl_vehicle = pd.read_csv('tblVehicle.csv')\n",
    "tbl_emission = pd.read_csv('tblEmission.csv')\n",
    "\n",
    "# join tbl_emission with dim_borough, dim_month, dim_year, and tbl_vehicle\n",
    "joined_data = pd.merge(tbl_emission, dim_borough, on='Borough')\\\n",
    "                .merge(dim_month, left_on=pd.to_datetime(tbl_emission['Date']).dt.month, right_on='month')\\\n",
    "                .merge(dim_year, left_on=pd.to_datetime(tbl_emission['Date']).dt.year, right_on='year')\\\n",
    "                .merge(tbl_vehicle, on=['Borough'])\n",
    "print(joined_data)\n",
    "\n",
    "# calculate the required averages\n",
    "averages = joined_data.groupby(['borough_id', 'year', 'month']).agg(\n",
    "    no2_cars_and_taxis=('no2', lambda x: x.mean() / joined_data['cars_and_taxis'].mean()),\n",
    "    no2_buses_and_coaches=('no2', lambda x: x.mean() / joined_data['buses_and_coaches'].mean()),\n",
    "    no2_motorbikes=('no2', lambda x: x.mean() / joined_data['motorbikes'].mean()),\n",
    "    no2_lgvs=('no2', lambda x: x.mean() / joined_data['lgvs'].mean()),\n",
    "    no2_hgvs=('no2', lambda x: x.mean() / joined_data['hgvs'].mean())\n",
    ").reset_index()\n",
    "\n",
    "# create the fact table by writing the DataFrame to a CSV file\n",
    "averages.to_csv('factq4.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e21e6fad-9954-414d-bc46-0a1b97a3afcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OLSInfluence' object has no attribute 'outlier_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# identify outliers and influential data points\u001b[39;00m\n\u001b[1;32m     17\u001b[0m infl \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_influence()\n\u001b[0;32m---> 18\u001b[0m outliers \u001b[38;5;241m=\u001b[39m \u001b[43minfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutlier_test\u001b[49m()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbonf(p)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.05\u001b[39m\n\u001b[1;32m     19\u001b[0m leverage \u001b[38;5;241m=\u001b[39m infl\u001b[38;5;241m.\u001b[39mhat_matrix_diag \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(infl\u001b[38;5;241m.\u001b[39mhat_matrix_diag)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# plot the data and highlight outliers and influential data points\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OLSInfluence' object has no attribute 'outlier_test'"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# assuming 'x' is the independent variable and 'y' is the dependent variable\n",
    "# 'data' is a pandas DataFrame that contains the data\n",
    "x = combined['All_Vehicles']\n",
    "y = combined['no2']\n",
    "\n",
    "# add a constant to the independent variable\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "# fit the regression model\n",
    "model = sm.OLS(y, x).fit()\n",
    "\n",
    "# identify outliers and influential data points\n",
    "infl = model.get_influence()\n",
    "outliers = infl.outlier_test()['bonf(p)'] < 0.05\n",
    "leverage = infl.hat_matrix_diag > 2 * np.mean(infl.hat_matrix_diag)\n",
    "\n",
    "# plot the data and highlight outliers and influential data points\n",
    "plt.scatter(x['All_Vehicles'], y)\n",
    "plt.scatter(x[outliers]['All_Vehicles'], y[outliers], color='r')\n",
    "plt.scatter(x[leverage]['All_Vehicles'], y[leverage], color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b65cfab-f7c4-4d9d-ab6b-8d3199ea4d00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
