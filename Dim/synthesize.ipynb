{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy \n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "class DistributionVehicles:\n",
    "    \n",
    "    def __init__(self):\n",
    "        ''' Predicts distribution of vehicles given just All_Vehicles '''\n",
    "        self.__df = pd.read_csv('missingData.csv')\n",
    "        self.__testData = pd.read_csv('vehicleFixed.csv')\n",
    "        self.__otherCols = self.__testData[['Date','Hour']]\n",
    "        self.__testData = self.__testData['All_Vehicles2'].to_numpy().reshape(-1, 1)\n",
    "        #print(self.__df.head)\n",
    "        self.splitData()\n",
    "    \n",
    "    def splitData(self):\n",
    "        ''' Splits dataset into training and test sets '''\n",
    "        self.__X_train, self.__X_test, self.__y_train, self.__y_test = train_test_split(self.__df[['All_Vehicles']], self.__df[['Cars_And_Taxis','Motorbikes','Buses_and_Coaches','LGVs','HGVs']], test_size=0.2, random_state=42)\n",
    "        \n",
    "    def selectModel(self,model):\n",
    "        ''' Select Model '''\n",
    "        self.__model = model\n",
    "        self.trainModel()\n",
    "        self.predict()\n",
    "    \n",
    "    def trainModel(self):\n",
    "        ''' Train Model ''' \n",
    "        self.__model.fit(self.__X_train, self.__y_train)\n",
    "        \n",
    "    def predict(self):\n",
    "        ''' Makes predictions using the trained model '''\n",
    "        predictions = self.__model.predict(self.__testData)\n",
    "        predictions = pd.DataFrame(predictions, columns=['Cars_And_Taxis','Motorbikes','Buses_and_Coaches','LGVs','HGVs']).round().abs()\n",
    "        #print(predictions.head)\n",
    "        predictions = pd.concat([pd.DataFrame(self.__otherCols),predictions,pd.DataFrame(self.__testData)],axis=1)\n",
    "        predictions = predictions.rename(columns={predictions.columns[-1]: 'All_Vehicles'})\n",
    "        #predictions['Borough'] = self.__testData['Borough']\n",
    "        #print(predictions)\n",
    "        self.write2File(predictions)\n",
    "        \n",
    "    def evaluate(self):\n",
    "        ''' Evaluate the performance of the selected model '''\n",
    "        r2 = r2_score(self.__y_test, self.__model.predict(self.__X_test))\n",
    "        print(\"R-squared value:\", r2)\n",
    "        \n",
    "    def write2File(self,dataframe):\n",
    "        dataframe.to_csv('vehicleFixed2.csv', index=False)\n",
    "    \n",
    "class ProcessData:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.__df = pd.read_csv('baseline.csv')\n",
    "        \n",
    "    def formatTime(self):\n",
    "        ''' Changes time from 7 -> 07:00:00 etc '''\n",
    "        self.__df['Starthour'] = self.__df['Starthour'].astype(str).str.zfill(2)\n",
    "        self.__df['Hour'] = self.__df['Starthour'] + ':00:00'\n",
    "        # print(self.__df)\n",
    "        \n",
    "    def remTime(self):\n",
    "        ''' Excludes all times not between 7am and 6pm '''\n",
    "        # Remove starthour\n",
    "        self.__df.drop('Starthour', axis=1, inplace=True)\n",
    "        # Convert to datatime\n",
    "        self.__df['Hour'] = pd.to_datetime(self.__df['Hour'], format='%H:%M:%S').dt.time\n",
    "        self.__df.set_index(pd.to_datetime(self.__df['Hour'], format='%H:%M:%S'), inplace=True)\n",
    "        # Filter time\n",
    "        self.__df = self.__df.between_time('07:00:00', '18:00:00')\n",
    "        self.__df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "    def saveDataset(self):\n",
    "        ''' Saves processed dataset '''\n",
    "        self.__df.to_csv('baselineProcessed.csv', index=False)\n",
    "\n",
    "class CombineDatasets:\n",
    "    \n",
    "    def __init__(self):\n",
    "        ''' Combines the datasets '''\n",
    "        self.__df1 = pd.read_csv('baselineProcessed.csv')\n",
    "        self.__df2 = pd.read_csv('missingData.csv')\n",
    "        self.joinDatasets()\n",
    "        self.multiDFs()\n",
    "\n",
    "    def joinDatasets(self):\n",
    "        ''' Set joins datasets '''\n",
    "        # append df2 to the bottom of df1\n",
    "        self.merged_df = self.__df1.append(self.__df2)\n",
    "        # group by Date and Hour, and count the number of rows in each group\n",
    "        counts = self.merged_df.groupby(['Date', 'Hour']).size().reset_index(name='count')\n",
    "        # create a list of Date and Hour combinations that appear 3 or more times\n",
    "        valid_combinations = counts[counts['count'] >= 3][['Date', 'Hour']]\n",
    "        # remove rows from the original dataframe where the Date and Hour combination appears less than 3 times\n",
    "        self.merged_df = self.merged_df.merge(valid_combinations, on=['Date', 'Hour'], how='inner')\n",
    "\n",
    "        # result: dataframe with rows removed where the Date and Hour combination appears less than 3 times\n",
    "        #print(self.merged_df)\n",
    "\n",
    "    def pivotData(self,df):\n",
    "        ''' Transposes data '''\n",
    "        # use pivot_table to transpose the dataframe\n",
    "        self.pivot_df = pd.pivot_table(df, values=['Cars_And_Taxis', 'Buses_and_Coaches', 'HGVs','LGVs','Motorbikes'], index=['Date', 'Hour'], columns=['Borough'], aggfunc='first')\n",
    "        # flatten the column names to a single level\n",
    "        self.pivot_df.columns = [f'{col[0]}_{col[1]}' for col in self.pivot_df.columns]\n",
    "        # reset the index to create separate columns for Date and Hour\n",
    "        self.pivot_df = self.pivot_df.reset_index()\n",
    "        return self.pivot_df\n",
    "    \n",
    "    def multiDFs(self):\n",
    "        ''' Seperate model is required for each model so... '''\n",
    "        self.df_Croydon = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Croydon'])]).dropna(axis=0)\n",
    "        self.df_Ealing = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Ealing'])]).dropna(axis=0)\n",
    "        self.df_Greenwich = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Greenwich'])]).dropna(axis=0)\n",
    "        self.df_Hillingdon = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Hillingdon'])]).dropna(axis=0)\n",
    "        self.df_Hounslow = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Hounslow'])]).dropna(axis=0)\n",
    "        self.df_Lambeth = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Lambeth'])]).dropna(axis=0)\n",
    "        self.df_Hackney = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Hackney'])]).dropna(axis=0)\n",
    "        self.df_Hammersmith_and_Fulham = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Hammersmith and Fulham'])]).dropna(axis=0)\n",
    "        self.df_Lewisham = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Lewisham'])]).dropna(axis=0)\n",
    "        self.df_Sutton = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Sutton'])]).dropna(axis=0)\n",
    "        self.df_Bromley = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Bromley'])]).dropna(axis=0)\n",
    "        self.df_Merton = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Merton'])]).dropna(axis=0)\n",
    "        self.df_Tower_Hamlets = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Tower Hamlets'])]).dropna(axis=0)\n",
    "        self.df_Wandsworth = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Wandsworth'])]).dropna(axis=0)\n",
    "        self.df_Westminister = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Westminister'])]).dropna(axis=0)\n",
    "        self.df_Brent = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Brent'])]).dropna(axis=0)\n",
    "        self.df_Redbridge = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Redbridge'])]).dropna(axis=0)\n",
    "        self.df_Waltham_Forest = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Waltham Forest'])]).dropna(axis=0)\n",
    "        self.df_Havering = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Havering'])]).dropna(axis=0)\n",
    "        self.df_Kensington_and_Chelsea = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Kensington and Cheslea'])]).dropna(axis=0)\n",
    "        self.df_Richmond_upon_Thames = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Richmond upon Thames'])]).dropna(axis=0)\n",
    "        self.df_Barnet = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Barnet'])]).dropna(axis=0)\n",
    "        self.df_Kingston_upon_Thames = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Kingston upon Thames'])]).dropna(axis=0)\n",
    "        self.df_City_of_London = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'City of London'])]).dropna(axis=0)\n",
    "        self.df_Cambden = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Cambden'])]).dropna(axis=0)\n",
    "        self.df_Barking_and_Dagenham = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Barking and Dagenham'])]).dropna(axis=0)\n",
    "        self.df_Islington = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Islington'])]).dropna(axis=0)\n",
    "        \n",
    "        self.df_Croydon.name = 'Croydon'\n",
    "        self.df_Ealing.name = 'Ealing'\n",
    "        self.df_Greenwich.name = 'Greenwich'\n",
    "        self.df_Hillingdon.name = 'Hillingdon'\n",
    "        self.df_Hounslow.name = 'Hounslow'\n",
    "        self.df_Lambeth.name = 'Lambeth'\n",
    "        self.df_Hackney.name = 'Hackney'\n",
    "        self.df_Hammersmith_and_Fulham.name = 'Hammersmith and Fulham'\n",
    "        self.df_Lewisham.name = 'Lewisham'\n",
    "        self.df_Sutton.name = 'Sutton'\n",
    "        self.df_Bromley.name = 'Bromley'\n",
    "        self.df_Merton.name = 'Merton'\n",
    "        self.df_Tower_Hamlets.name = 'Tower Hamlets'\n",
    "        self.df_Wandsworth.name = 'Wandsworth'\n",
    "        self.df_Brent.name = 'Brent'\n",
    "        self.df_Redbridge.name = 'Redbridge'\n",
    "        self.df_Waltham_Forest.name = 'Waltham Forest'\n",
    "        self.df_Havering.name = 'Havering'\n",
    "        self.df_Richmond_upon_Thames.name = 'Richmond upon Thames'\n",
    "        self.df_Barnet.name = 'Barnet'\n",
    "        self.df_Kingston_upon_Thames.name = 'Kingston upon Thames'\n",
    "        self.df_City_of_London.name = 'City of London'\n",
    "        self.df_Barking_and_Dagenham.name = 'Barking and Dagenham'\n",
    "        self.df_Islington.name = 'Islington'\n",
    "        \n",
    "        self.dfList = [\n",
    "            self.df_Croydon,\n",
    "            self.df_Ealing,\n",
    "            self.df_Greenwich,\n",
    "            self.df_Hillingdon,\n",
    "            self.df_Hounslow,\n",
    "            self.df_Lambeth, \n",
    "            self.df_Hackney,\n",
    "            self.df_Hammersmith_and_Fulham,\n",
    "            self.df_Lewisham,\n",
    "            self.df_Sutton,\n",
    "            self.df_Bromley,\n",
    "            self.df_Merton,\n",
    "            self.df_Tower_Hamlets,\n",
    "            self.df_Wandsworth,\n",
    "            self.df_Brent,\n",
    "            self.df_Redbridge,\n",
    "            self.df_Waltham_Forest,\n",
    "            self.df_Havering,\n",
    "            self.df_Richmond_upon_Thames,\n",
    "            self.df_Barnet,\n",
    "            self.df_Kingston_upon_Thames,\n",
    "            self.df_City_of_London,\n",
    "            self.df_Barking_and_Dagenham,\n",
    "            self.df_Islington\n",
    "        ]\n",
    "        \n",
    "    def saveDataset(self):\n",
    "        ''' Saves processed dataset '''\n",
    "        self.merged_df.to_csv('joinedDataset.csv', index=False)\n",
    "        \n",
    "    \n",
    "class PredictBoroughVolume(CombineDatasets):\n",
    "    \n",
    "    def __init__(self):\n",
    "        ''' Predicts traffic levels in each borough based on volume in our baseline dataset '''\n",
    "        super().__init__()\n",
    "        \n",
    "        self.__predictor = pd.read_csv('baseline.csv')\n",
    "        self.formatPredictor()\n",
    "        self.filledBoroughs = []\n",
    "        for borough in self.dfList:\n",
    "            self.__df = borough\n",
    "            self.boroughName = borough.name\n",
    "            self.splitData()\n",
    "            self.trainModel()\n",
    "            self.fillMissing()\n",
    "        self.combineList()\n",
    "        self.saveData()\n",
    "            \n",
    "    def combineList(self): \n",
    "        ''' Combines the list of dataframes to a single for saving '''\n",
    "        self.final = pd.concat(self.filledBoroughs)\n",
    "        self.final = self.final.reindex(columns=['Date', 'Hour', 'Borough', 'Cars_And_Taxis','Buses_and_Coaches','Motorbikes','LGVs','HGVs'])\n",
    "        # Remove decimals\n",
    "        self.final.iloc[:, 3:8] = self.final.iloc[:, 3:8].astype(int)\n",
    "        # Add all vehicles\n",
    "        self.final['All_Vehicles'] = self.final.iloc[:, 3:8].sum(axis=1)\n",
    "        print(self.final.head)\n",
    "        \n",
    "    def saveData(self):\n",
    "        ''' Saves dataframe as csv files '''\n",
    "        self.final.to_csv('finalVehicle.csv', index=False)\n",
    "\n",
    "    def splitData(self):\n",
    "        ''' Splits data into training and test set '''\n",
    "        self.__X_train, self.__X_test, self.__y_train, self.__y_test = train_test_split(self.__df.iloc[:, [2,4,6,8,10]], self.__df.iloc[:, [3,5,7,9,11]], test_size=0.2, random_state=42)\n",
    "\n",
    "    def trainModel(self):\n",
    "        ''' Trains model '''\n",
    "        self.__model = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42, max_iter=1000)\n",
    "        self.__model.fit(self.__X_train, self.__y_train)\n",
    "    \n",
    "    def predict(self):\n",
    "        ''' Used to predict and evaluate model '''\n",
    "        #print(self.__X_test)\n",
    "        y_pred = self.__model.predict(self.__X_test)\n",
    "        r2 = r2_score(self.__y_test, y_pred)\n",
    "        print(y_pred)\n",
    "        #print(\"R-squared:\", r2)\n",
    "    \n",
    "    def fillMissing(self):\n",
    "        ''' Fill missing data for one borough '''\n",
    "        columns = ['Buses_and_Coaches','Cars_And_Taxis','HGVs','LGVs','Motorbikes']\n",
    "        self.df_predictions = (self.__model.predict(self.__predictorProcessed)).round()\n",
    "        #print(self.df_predictions)\n",
    "        self.df_predictions = pd.DataFrame(self.df_predictions, columns=columns)\n",
    "        # Append Date and Starthour\n",
    "        self.df_predictions = pd.concat([pd.DataFrame(self.__predictor[['Date','Starthour']]), self.df_predictions], axis=1, sort=False)\n",
    "        self.df_predictions = self.formatTime(self.df_predictions)\n",
    "        self.df_predictions = self.remTime(self.df_predictions)\n",
    "        self.df_predictions['Date'] = pd.to_datetime(self.df_predictions['Date'])\n",
    "        self.df_predictions = self.df_predictions[~(self.df_predictions['Date'].dt.year.isin([2017, 2022]))]\n",
    "        #print(self.df_predictions)\n",
    "        # Append Borough name\n",
    "        self.df_predictions['Borough'] = self.boroughName \n",
    "        #print(self.df_predictions)\n",
    "        self.filledBoroughs.append(self.df_predictions)\n",
    "           \n",
    "    def formatTime(self,df):\n",
    "        ''' Changes time from 7 -> 07:00:00 etc '''\n",
    "        df['Starthour'] = df['Starthour'].astype(str).str.zfill(2)\n",
    "        df['Hour'] = df['Starthour'] + ':00:00'\n",
    "        return df\n",
    "        \n",
    "    def remTime(self,df):\n",
    "        ''' Excludes all times not between 7am and 6pm '''\n",
    "        # Remove starthour\n",
    "        df.drop('Starthour', axis=1, inplace=True)\n",
    "        # Convert to datatime\n",
    "        df['Hour'] = pd.to_datetime(df['Hour'], format='%H:%M:%S').dt.time\n",
    "        df.set_index(pd.to_datetime(df['Hour'], format='%H:%M:%S'), inplace=True)\n",
    "        # Filter time\n",
    "        df = df.between_time('07:00:00', '18:00:00')\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        return df\n",
    "        \n",
    "    def formatPredictor(self):\n",
    "        ''' Orders predictor as Bus | Car | HGVs | LGVs | Motorbikes '''\n",
    "        self.__predictorProcessed = self.__predictor[['Buses_and_Coaches','Cars_And_Taxis','HGVs','LGVs','Motorbikes']]\n",
    "        \n",
    "\n",
    "distVehicle = DistributionVehicles()\n",
    "distVehicle.selectModel(LinearRegression())\n",
    "\n",
    "\n",
    "'''\n",
    "print('Linear Regression:')\n",
    "distVehicle.evaluate()\n",
    "'''\n",
    "'''\n",
    "p = ProcessData()\n",
    "p.formatTime()\n",
    "p.remTime()\n",
    "p.saveDataset()\n",
    "'''\n",
    "#c = PredictBoroughVolume()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                      Borough      Hour        Date        no2  Cars_And_Taxis  \\\n",
      "0       Barking and Dagenham  07:00:00  2018-01-01   4.374397           196.0   \n",
      "1       Barking and Dagenham  08:00:00  2018-01-01   5.217581           216.0   \n",
      "2       Barking and Dagenham  09:00:00  2018-01-01   8.640386           299.0   \n",
      "3       Barking and Dagenham  10:00:00  2018-01-01   9.640889           323.0   \n",
      "4       Barking and Dagenham  11:00:00  2018-01-01  10.846112           352.0   \n",
      "...                      ...       ...         ...        ...             ...   \n",
      "229645            Wandsworth  14:00:00  2021-12-31  37.946213          1001.0   \n",
      "229646            Wandsworth  15:00:00  2021-12-31  40.464169          1062.0   \n",
      "229647            Wandsworth  16:00:00  2021-12-31  46.568785          1208.0   \n",
      "229648            Wandsworth  17:00:00  2021-12-31  36.202377           959.0   \n",
      "229649            Wandsworth  18:00:00  2021-12-31  47.718706          1235.0   \n",
      "\n",
      "        Motorbikes  Buses_and_Coaches   LGVs  HGVs  All_Vehicles  \n",
      "0             14.0               18.0   33.0   0.0         254.0  \n",
      "1             14.0               18.0   39.0   0.0         282.0  \n",
      "2             17.0               19.0   62.0   3.0         399.0  \n",
      "3             17.0               19.0   68.0   6.0         433.0  \n",
      "4             18.0               19.0   76.0   9.0         474.0  \n",
      "...            ...                ...    ...   ...           ...  \n",
      "229645        38.0               25.0  256.0  75.0        1395.0  \n",
      "229646        39.0               26.0  273.0  81.0        1481.0  \n",
      "229647        44.0               27.0  314.0  96.0        1688.0  \n",
      "229648        36.0               25.0  245.0  71.0        1336.0  \n",
      "229649        45.0               27.0  321.0  99.0        1727.0  \n",
      "\n",
      "[229650 rows x 10 columns]>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Join vehicleFixed and vehicleFixed2 on date, hour and All_vehicle/All_vehicle2\n",
    "df1 = pd.read_csv('vehicleFixed.csv')\n",
    "df2 = pd.read_csv('vehicleFixed2.csv')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# If the column names are different in the two dataframes, you can specify them explicitly:\n",
    "merged_df = pd.merge(df1, df2, left_on=['Hour', 'Date', 'All_Vehicles2'], right_on=['Hour', 'Date', 'All_Vehicles'])\n",
    "merged_df = merged_df.drop(\"All_Vehicles2\", axis=1)\n",
    "merged_df = merged_df.drop(\"Unnamed: 0\", axis=1)\n",
    "print(merged_df.head)\n",
    "merged_df.to_csv('tblVehicleFinal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of         Cars_And_Taxis  Motorbikes  Buses_and_Coaches   LGVs  HGVs\n",
      "0                196.0        14.0               18.0   33.0   0.0\n",
      "1                216.0        14.0               18.0   39.0   0.0\n",
      "2                299.0        17.0               19.0   62.0   3.0\n",
      "3                323.0        17.0               19.0   68.0   6.0\n",
      "4                352.0        18.0               19.0   76.0   9.0\n",
      "...                ...         ...                ...    ...   ...\n",
      "227911          1001.0        38.0               25.0  256.0  75.0\n",
      "227912          1062.0        39.0               26.0  273.0  81.0\n",
      "227913          1208.0        44.0               27.0  314.0  96.0\n",
      "227914           959.0        36.0               25.0  245.0  71.0\n",
      "227915          1235.0        45.0               27.0  321.0  99.0\n",
      "\n",
      "[227916 rows x 5 columns]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" print('Linear Regression:') distVehicle.evaluate()  p = ProcessData() p.formatTime() p.remTime() p.saveDataset() \""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.svm import SVR \n",
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.neural_network import MLPRegressor \n",
    "import numpy \n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "class DistributionVehicles:\n",
    "\n",
    "    def __init__(self):\n",
    "        ''' Predicts distribution of vehicles given just All_Vehicles '''\n",
    "        self.__df = pd.read_csv('missingData.csv')\n",
    "        self.__testData = pd.read_csv('vehicleFixed.csv')\n",
    "        self.__otherCols = self.__testData[['Date','Hour']]\n",
    "        self.__testData = self.__testData['All_Vehicles2'].to_numpy().reshape(-1, 1)\n",
    "        #print(self.__df.head)\n",
    "        self.splitData()\n",
    "\n",
    "    def splitData(self):\n",
    "        ''' Splits dataset into training and test sets '''\n",
    "        self.__X_train, self.__X_test, self.__y_train, self.__y_test = train_test_split(self.__df[['All_Vehicles']], self.__df[['Cars_And_Taxis','Motorbikes','Buses_and_Coaches','LGVs','HGVs']], test_size=0.2, random_state=42)\n",
    "\n",
    "    def selectModel(self,model):\n",
    "        ''' Select Model '''\n",
    "        self.__model = model\n",
    "        self.trainModel()\n",
    "        self.predict()\n",
    "\n",
    "    def trainModel(self):\n",
    "        ''' Train Model ''' \n",
    "        self.__model.fit(self.__X_train, self.__y_train)\n",
    "\n",
    "    def predict(self):\n",
    "        ''' Makes predictions using the trained model '''\n",
    "        predictions = self.__model.predict(self.__testData)\n",
    "        predictions = pd.DataFrame(predictions, columns=['Cars_And_Taxis','Motorbikes','Buses_and_Coaches','LGVs','HGVs']).round()\n",
    "        for k, v in predictions.iteritems():\n",
    "            v[v < 0] = 0\n",
    "        print(predictions.head)\n",
    "        predictions = pd.concat([pd.DataFrame(self.__otherCols),predictions,pd.DataFrame(self.__testData)],axis=1)\n",
    "        predictions = predictions.rename(columns={predictions.columns[-1]: 'All_Vehicles'})\n",
    "        #predictions['Borough'] = self.__testData['Borough']\n",
    "        #print(predictions)\n",
    "        self.write2File(predictions)\n",
    "\n",
    "    def evaluate(self):\n",
    "        ''' Evaluate the performance of the selected model '''\n",
    "        r2 = r2_score(self.__y_test, self.__model.predict(self.__X_test))\n",
    "        print(\"R-squared value:\", r2)\n",
    "\n",
    "    def write2File(self,dataframe):\n",
    "        dataframe.to_csv('vehicleFixed2.csv', index=False)\n",
    "        \n",
    "    class ProcessData:\n",
    "\n",
    "        def __init__(self):\n",
    "            self.__df = pd.read_csv('baseline.csv')\n",
    "\n",
    "        def formatTime(self):\n",
    "            ''' Changes time from 7 -> 07:00:00 etc '''\n",
    "            self.__df['Starthour'] = self.__df['Starthour'].astype(str).str.zfill(2)\n",
    "            self.__df['Hour'] = self.__df['Starthour'] + ':00:00'\n",
    "            # print(self.__df)\n",
    "\n",
    "        def remTime(self):\n",
    "            ''' Excludes all times not between 7am and 6pm '''\n",
    "            # Remove starthour\n",
    "            self.__df.drop('Starthour', axis=1, inplace=True)\n",
    "            # Convert to datatime\n",
    "            self.__df['Hour'] = pd.to_datetime(self.__df['Hour'], format='%H:%M:%S').dt.time\n",
    "            self.__df.set_index(pd.to_datetime(self.__df['Hour'], format='%H:%M:%S'), inplace=True)\n",
    "            # Filter time\n",
    "            self.__df = self.__df.between_time('07:00:00', '18:00:00')\n",
    "            self.__df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        def saveDataset(self):\n",
    "            ''' Saves processed dataset '''\n",
    "            self.__df.to_csv('baselineProcessed.csv', index=False)\n",
    "            \n",
    "class CombineDatasets:\n",
    "\n",
    "    def __init__(self):\n",
    "        ''' Combines the datasets '''\n",
    "        self.__df1 = pd.read_csv('baselineProcessed.csv')\n",
    "        self.__df2 = pd.read_csv('missingData.csv')\n",
    "        self.joinDatasets()\n",
    "        self.multiDFs()\n",
    "\n",
    "    def joinDatasets(self):\n",
    "        ''' Set joins datasets '''\n",
    "        # append df2 to the bottom of df1\n",
    "        self.merged_df = self.__df1.append(self.__df2)\n",
    "        # group by Date and Hour, and count the number of rows in each group\n",
    "        counts = self.merged_df.groupby(['Date', 'Hour']).size().reset_index(name='count')\n",
    "        # create a list of Date and Hour combinations that appear 3 or more times\n",
    "        valid_combinations = counts[counts['count'] >= 3][['Date', 'Hour']]\n",
    "        # remove rows from the original dataframe where the Date and Hour combination appears less than 3 times\n",
    "        self.merged_df = self.merged_df.merge(valid_combinations, on=['Date', 'Hour'], how='inner')\n",
    "\n",
    "        # result: dataframe with rows removed where the Date and Hour combination appears less than 3 times\n",
    "        #print(self.merged_df)\n",
    "\n",
    "    def pivotData(self,df):\n",
    "        ''' Transposes data '''\n",
    "        # use pivot_table to transpose the dataframe\n",
    "        self.pivot_df = pd.pivot_table(df, values=['Cars_And_Taxis', 'Buses_and_Coaches', 'HGVs','LGVs','Motorbikes'], index=['Date', 'Hour'], columns=['Borough'], aggfunc='first')\n",
    "        # flatten the column names to a single level\n",
    "        self.pivot_df.columns = [f'{col[0]}_{col[1]}' for col in self.pivot_df.columns]\n",
    "        # reset the index to create separate columns for Date and Hour\n",
    "        self.pivot_df = self.pivot_df.reset_index()\n",
    "        return self.pivot_df\n",
    "\n",
    "    def multiDFs(self):\n",
    "        ''' Seperate model is required for each model so... '''\n",
    "        self.df_Croydon = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Croydon'])]).dropna(axis=0)\n",
    "        self.df_Ealing = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Ealing'])]).dropna(axis=0)\n",
    "        self.df_Greenwich = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Greenwich'])]).dropna(axis=0)\n",
    "        self.df_Hillingdon = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Hillingdon'])]).dropna(axis=0)\n",
    "        self.df_Hounslow = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Hounslow'])]).dropna(axis=0)\n",
    "        self.df_Lambeth = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Lambeth'])]).dropna(axis=0)\n",
    "        self.df_Hackney = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Hackney'])]).dropna(axis=0)\n",
    "        self.df_Hammersmith_and_Fulham = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Hammersmith and Fulham'])]).dropna(axis=0)\n",
    "        self.df_Lewisham = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Lewisham'])]).dropna(axis=0)\n",
    "        self.df_Sutton = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Sutton'])]).dropna(axis=0)\n",
    "        self.df_Bromley = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Bromley'])]).dropna(axis=0)\n",
    "        self.df_Merton = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Merton'])]).dropna(axis=0)\n",
    "        self.df_Tower_Hamlets = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Tower Hamlets'])]).dropna(axis=0)\n",
    "        self.df_Wandsworth = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Wandsworth'])]).dropna(axis=0)\n",
    "        self.df_Westminister = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Westminister'])]).dropna(axis=0)\n",
    "        self.df_Brent = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Brent'])]).dropna(axis=0)\n",
    "        self.df_Redbridge = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Redbridge'])]).dropna(axis=0)\n",
    "        self.df_Waltham_Forest = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Waltham Forest'])]).dropna(axis=0)\n",
    "        self.df_Havering = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Havering'])]).dropna(axis=0)\n",
    "        self.df_Kensington_and_Chelsea = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Kensington and Cheslea'])]).dropna(axis=0)\n",
    "        self.df_Richmond_upon_Thames = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Richmond upon Thames'])]).dropna(axis=0)\n",
    "        self.df_Barnet = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Barnet'])]).dropna(axis=0)\n",
    "        self.df_Kingston_upon_Thames = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Kingston upon Thames'])]).dropna(axis=0)\n",
    "        self.df_City_of_London = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'City of London'])]).dropna(axis=0)\n",
    "        self.df_Cambden = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Cambden'])]).dropna(axis=0)\n",
    "        self.df_Barking_and_Dagenham = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Barking and Dagenham'])]).dropna(axis=0)\n",
    "        self.df_Islington = self.pivotData(self.merged_df[self.merged_df['Borough'].isin(['Marlybone Road', 'Islington'])]).dropna(axis=0)\n",
    "\n",
    "        self.df_Croydon.name = 'Croydon'\n",
    "        self.df_Ealing.name = 'Ealing'\n",
    "        self.df_Greenwich.name = 'Greenwich'\n",
    "        self.df_Hillingdon.name = 'Hillingdon'\n",
    "        self.df_Hounslow.name = 'Hounslow'\n",
    "        self.df_Lambeth.name = 'Lambeth'\n",
    "        self.df_Hackney.name = 'Hackney'\n",
    "        self.df_Hammersmith_and_Fulham.name = 'Hammersmith and Fulham'\n",
    "        self.df_Lewisham.name = 'Lewisham'\n",
    "        self.df_Sutton.name = 'Sutton'\n",
    "        self.df_Bromley.name = 'Bromley'\n",
    "        self.df_Merton.name = 'Merton'\n",
    "        self.df_Tower_Hamlets.name = 'Tower Hamlets'\n",
    "        self.df_Wandsworth.name = 'Wandsworth'\n",
    "        self.df_Brent.name = 'Brent'\n",
    "        self.df_Redbridge.name = 'Redbridge'\n",
    "        self.df_Waltham_Forest.name = 'Waltham Forest'\n",
    "        self.df_Havering.name = 'Havering'\n",
    "        self.df_Richmond_upon_Thames.name = 'Richmond upon Thames'\n",
    "        self.df_Barnet.name = 'Barnet'\n",
    "        self.df_Kingston_upon_Thames.name = 'Kingston upon Thames'\n",
    "        self.df_City_of_London.name = 'City of London'\n",
    "        self.df_Barking_and_Dagenham.name = 'Barking and Dagenham'\n",
    "        self.df_Islington.name = 'Islington'\n",
    "\n",
    "        self.dfList = [\n",
    "            self.df_Croydon,\n",
    "            self.df_Ealing,\n",
    "            self.df_Greenwich,\n",
    "            self.df_Hillingdon,\n",
    "            self.df_Hounslow,\n",
    "            self.df_Lambeth, \n",
    "            self.df_Hackney,\n",
    "            self.df_Hammersmith_and_Fulham,\n",
    "            self.df_Lewisham,\n",
    "            self.df_Sutton,\n",
    "            self.df_Bromley,\n",
    "            self.df_Merton,\n",
    "            self.df_Tower_Hamlets,\n",
    "            self.df_Wandsworth,\n",
    "            self.df_Brent,\n",
    "            self.df_Redbridge,\n",
    "            self.df_Waltham_Forest,\n",
    "            self.df_Havering,\n",
    "            self.df_Richmond_upon_Thames,\n",
    "            self.df_Barnet,\n",
    "            self.df_Kingston_upon_Thames,\n",
    "            self.df_City_of_London,\n",
    "            self.df_Barking_and_Dagenham,\n",
    "            self.df_Islington\n",
    "        ]\n",
    "\n",
    "    def saveDataset(self):\n",
    "        ''' Saves processed dataset '''\n",
    "        self.merged_df.to_csv('joinedDataset.csv', index=False)\n",
    "        \n",
    "class PredictBoroughVolume(CombineDatasets):\n",
    "\n",
    "    def __init__(self):\n",
    "        ''' Predicts traffic levels in each borough based on volume in our baseline dataset '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.__predictor = pd.read_csv('baseline.csv')\n",
    "        self.formatPredictor()\n",
    "        self.filledBoroughs = []\n",
    "        for borough in self.dfList:\n",
    "            self.__df = borough\n",
    "            self.boroughName = borough.name\n",
    "            self.splitData()\n",
    "            self.trainModel()\n",
    "            self.fillMissing()\n",
    "        self.combineList()\n",
    "        self.saveData()\n",
    "\n",
    "    def combineList(self): \n",
    "        ''' Combines the list of dataframes to a single for saving '''\n",
    "        self.final = pd.concat(self.filledBoroughs)\n",
    "        self.final = self.final.reindex(columns=['Date', 'Hour', 'Borough', 'Cars_And_Taxis','Buses_and_Coaches','Motorbikes','LGVs','HGVs'])\n",
    "        # Remove decimals\n",
    "        self.final.iloc[:, 3:8] = self.final.iloc[:, 3:8].astype(int)\n",
    "        # Add all vehicles\n",
    "        self.final['All_Vehicles'] = self.final.iloc[:, 3:8].sum(axis=1)\n",
    "        print(self.final.head)\n",
    "\n",
    "    def saveData(self):\n",
    "        ''' Saves dataframe as csv files '''\n",
    "        self.final.to_csv('finalVehicle.csv', index=False)\n",
    "\n",
    "    def splitData(self):\n",
    "        ''' Splits data into training and test set '''\n",
    "        self.__X_train, self.__X_test, self.__y_train, self.__y_test = train_test_split(self.__df.iloc[:, [2,4,6,8,10]], self.__df.iloc[:, [3,5,7,9,11]], test_size=0.2, random_state=42)\n",
    "\n",
    "    def trainModel(self):\n",
    "        ''' Trains model '''\n",
    "        self.__model = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42, max_iter=1000)\n",
    "        self.__model.fit(self.__X_train, self.__y_train)\n",
    "\n",
    "    def predict(self):\n",
    "        ''' Used to predict and evaluate model '''\n",
    "        #print(self.__X_test)\n",
    "        y_pred = self.__model.predict(self.__X_test)\n",
    "        r2 = r2_score(self.__y_test, y_pred)\n",
    "        print(y_pred)\n",
    "        #print(\"R-squared:\", r2)\n",
    "\n",
    "    def fillMissing(self):\n",
    "        ''' Fill missing data for one borough '''\n",
    "        columns = ['Buses_and_Coaches','Cars_And_Taxis','HGVs','LGVs','Motorbikes']\n",
    "        self.df_predictions = (self.__model.predict(self.__predictorProcessed)).round()\n",
    "        #print(self.df_predictions)\n",
    "        self.df_predictions = pd.DataFrame(self.df_predictions, columns=columns)\n",
    "        # Append Date and Starthour\n",
    "        self.df_predictions = pd.concat([pd.DataFrame(self.__predictor[['Date','Starthour']]), self.df_predictions], axis=1, sort=False)\n",
    "        self.df_predictions = self.formatTime(self.df_predictions)\n",
    "        self.df_predictions = self.remTime(self.df_predictions)\n",
    "        self.df_predictions['Date'] = pd.to_datetime(self.df_predictions['Date'])\n",
    "        self.df_predictions = self.df_predictions[~(self.df_predictions['Date'].dt.year.isin([2017, 2022]))]\n",
    "        #print(self.df_predictions)\n",
    "        # Append Borough name\n",
    "        self.df_predictions['Borough'] = self.boroughName \n",
    "        #print(self.df_predictions)\n",
    "        self.filledBoroughs.append(self.df_predictions)\n",
    "\n",
    "    def formatTime(self,df):\n",
    "        ''' Changes time from 7 -> 07:00:00 etc '''\n",
    "        df['Starthour'] = df['Starthour'].astype(str).str.zfill(2)\n",
    "        df['Hour'] = df['Starthour'] + ':00:00'\n",
    "        return df\n",
    "\n",
    "    def remTime(self,df):\n",
    "        ''' Excludes all times not between 7am and 6pm '''\n",
    "        # Remove starthour\n",
    "        df.drop('Starthour', axis=1, inplace=True)\n",
    "        # Convert to datatime\n",
    "        df['Hour'] = pd.to_datetime(df['Hour'], format='%H:%M:%S').dt.time\n",
    "        df.set_index(pd.to_datetime(df['Hour'], format='%H:%M:%S'), inplace=True)\n",
    "        # Filter time\n",
    "        df = df.between_time('07:00:00', '18:00:00')\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        return df\n",
    "\n",
    "    def formatPredictor(self):\n",
    "        ''' Orders predictor as Bus | Car | HGVs | LGVs | Motorbikes '''\n",
    "        self.__predictorProcessed = self.__predictor[['Buses_and_Coaches','Cars_And_Taxis','HGVs','LGVs','Motorbikes']]\n",
    "        \n",
    "distVehicle = DistributionVehicles() \n",
    "distVehicle.selectModel(LinearRegression())\n",
    "\n",
    "''' print('Linear Regression:') distVehicle.evaluate() ''' ''' p = ProcessData() p.formatTime() p.remTime() p.saveDataset() '''\n",
    "\n",
    "#c = PredictBoroughVolume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
